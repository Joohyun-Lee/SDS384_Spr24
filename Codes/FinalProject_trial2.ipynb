{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d8e54-c3c4-4d4a-8e64-f0d3d573996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data \n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "snap = 99\n",
    "df=pd.read_csv(\"halodata_tng100-1_{}th_logadded.csv\".format(snap))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772df01b-7719-4bc3-81a7-6fb532947a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assume you have independent variables X and a dependent variable y\n",
    "features = ['logSubhaloMassType0', 'logSubhaloMassType1', 'logSubhaloMassType4',\n",
    "       'logSubhaloSpin', 'logSubhaloVmax', 'logSubhaloVmaxRad',\n",
    "       'logSubhaloStarMetallicity', 'logSubhaloGasMetallicity',\n",
    "       'logSubhaloSFR']\n",
    "dependent_var = ['logSubhaloBHMass']\n",
    "df_t = df[(df['logSubhaloMassType0'] > -90) & (df['logSubhaloMassType4'] > -90) &\n",
    "   (df['SubhaloStarMetallicity'] > -90) & (df['SubhaloStarMetallicity'] > -90) & (df['SubhaloGasMetallicity'] > -90)]\n",
    "X = df_t[features]\n",
    "y = df_t[dependent_var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Create and fit the linear regression model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train.values.ravel())\n",
    "# Print the coefficients of the model\n",
    "print(reg.coef_, reg.intercept_)\n",
    "print(reg.score(X, y))\n",
    "\n",
    "# Make predictions using the model\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Flatten the predictions and actual values if necessary\n",
    "actual_values_ln = y_test.values.flatten()  # Assuming y_test is a DataFrame\n",
    "predicted_values_ln = y_pred.flatten()  # Flatten predictions array\n",
    "\n",
    "# Compute the Mean Squared Error\n",
    "mse = mean_squared_error(actual_values_ln, predicted_values_ln)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test.iloc[:, 0], y=y_pred, alpha=0.4)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--') # A line representing perfect predictions\n",
    "plt.text(s=f'MSE: {mse:.5f}', x=y_test.min(), y=y_pred.max(), fontsize=20, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.xlabel('Actual SubhaloBHMass',fontsize=20)\n",
    "plt.ylabel('Predicted SubhaloBHMass',fontsize=20)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.text(s=f'MSE: {mse:.5f}', x=y_test.min(), y=y_pred.max(), fontsize=20, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.savefig('LinearRegression.jpg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = reg.coef_\n",
    "feature_names = X.columns\n",
    "feature_importance = pd.DataFrame(coefficients, index=feature_names, columns=['Coefficient'])\n",
    "\n",
    "# Sort features by their coefficient values\n",
    "feature_importance.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "\n",
    "print(feature_importance)\n",
    "# Plotting feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=feature_importance['Coefficient'], y=feature_importance.index)\n",
    "plt.title('Feature Importance in Linear Regression')\n",
    "plt.xlabel('Coefficient Magnitude')\n",
    "plt.ylabel('Features')\n",
    "plt.savefig('LinearReg.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989c7e4-d347-4adf-bbc3-919e609e0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "spt=np.ones_like(df_t['logSubhaloVmax'])*0.1\n",
    "print(s)\n",
    "plt.scatter(df_t['logSubhaloVmax'],df_t['logSubhaloBHMass'], s=spt)\n",
    "plt.title('Feature Importance in Linear Regression',fontsize=15)\n",
    "plt.xlabel('SubhaloVmax (log10(km/s))',fontsize=15)\n",
    "plt.ylabel('SubhaloBHMass (log10[SubhaloBHMass/M_solar])',fontsize=15)\n",
    "plt.savefig('SubhaloVmax.jpg')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_t['logSubhaloMassType4'],df_t['logSubhaloBHMass'],s=spt)\n",
    "plt.title('Feature Importance in Linear Regression',fontsize=15)\n",
    "plt.xlabel('SubhaloMassType4  (log10[Star_Mass/M_solar])',fontsize=15)\n",
    "plt.ylabel('SubhaloBHMass (log10[SubhaloBHMass/M_solar])',fontsize=15)\n",
    "plt.savefig('SubhaloMassType4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300208ea-f81d-4cd7-ba45-438d4028e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(reg, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[100])\n",
    "shap.plots.beeswarm(shap_values)\n",
    "\n",
    "importances = reg.feature_importances_\n",
    "feature_importances = dict(zip(features, importances))\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "importances_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importances_df)\n",
    "plt.title('Feature Importances in RandomForestRegressor',fontsize=16)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdea245-210f-4c70-b7b8-407d90b5c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_regressor = RandomForestRegressor(n_estimators=50, random_state=42, max_depth=12)\n",
    "\n",
    "# Train the model\n",
    "forest_regressor.fit(X_train, y_train.values.ravel())  # .values.ravel() to convert it to 1D array if y_train is a DataFrame\n",
    "\n",
    "# Make predictions\n",
    "y_pred = forest_regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Flatten the predictions and actual values if necessary\n",
    "actual_values_rf = y_test.values.flatten()  # Assuming y_test is a DataFrame\n",
    "predicted_values_rf = y_pred.flatten()  # Flatten predictions array\n",
    "\n",
    "# Compute the Mean Squared Error\n",
    "mse = mean_squared_error(actual_values_rf, predicted_values_rf)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "# Plotting Actual vs. Predicted Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test.iloc[:, 0], y=y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Ideal line where actual = predicted\n",
    "plt.text(s=f'MSE: {mse:.5f}', x=y_test.min(), y=y_pred.max(), fontsize=20, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.xlabel('Actual SubhaloBHMass',fontsize=20)\n",
    "plt.ylabel('Predicted SubhaloBHMass',fontsize=20)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.text(s=f'MSE: {mse:.5f}', x=y_test.min(), y=y_pred.max(), fontsize=20, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.savefig(\"RandomForest.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f779240d-6149-475f-bc59-99657a1188f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "max_depths = [2, 4, 8, 10, 12, 15, 20, 30]\n",
    "mse = []\n",
    "r2=[]\n",
    "roc=[]\n",
    "for i, max_depth in enumerate(max_depths):\n",
    "    params = {\n",
    "    \"n_estimators\": 50,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": 5\n",
    "    }\n",
    "    forest_regressor = RandomForestRegressor(**params)\n",
    "\n",
    "    # Train the model\n",
    "    forest_regressor.fit(X_train, y_train.values.ravel()) \n",
    "    y_pred_test=forest_regressor.predict(X_test)\n",
    "    \n",
    "    mse += [mean_squared_error(y_test, y_pred_test)]\n",
    "    r2 +=[r2_score(y_test, y_pred_test)]\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths,mse)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths,r2)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('R2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aeaff1-aeb3-415c-8088-0c7612979b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(forest_regressor, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[100])\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766d897-546a-46f7-9df5-5ef747e682de",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = forest_regressor.feature_importances_\n",
    "feature_importances = dict(zip(features, importances))\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "importances_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importances_df)\n",
    "plt.title('Feature Importances in RandomForestRegressor')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8310d-5cdb-4037-b7ec-0d9d6d7816f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths,mse,'-o')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9455685-a8e2-4e4e-bae3-e780f7be8291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data scaling (optional but recommended)\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_torch = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_torch = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "X_test_torch = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_torch = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "test_dataset = TensorDataset(X_test_torch, y_test_torch)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.activation(self.fc4(x))\n",
    "        return self.output(x)\n",
    "\n",
    "# Initialize the model\n",
    "model = RegressionNet(X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ca532-4aa3-4cd6-9773-6b5a9211bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "train(model, train_loader, criterion, optimizer, epochs=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_torch).numpy()\n",
    "    predictions = scaler_y.inverse_transform(predictions)  # Rescale to original scale\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatter(y_test, predictions, alpha=0.5, color='red', label='Predicted vs Actual')\n",
    "plt.xlabel('Actual Values',fontsize=16)\n",
    "plt.ylabel('Predicted Values',fontsize=16)\n",
    "plt.title('Actual vs. Predicted Values',fontsize=16)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb04fa-f80f-4c3a-8d59-04a9c2c619ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[:,0])\n",
    "print(y_test['logSubhaloBHMass'])\n",
    "print(y_test.iloc[:, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b2fcb-d28d-42f8-84a0-da422a680599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Flatten the predictions and actual values if necessary\n",
    "actual_values = y_test.values.flatten()  # Assuming y_test is a DataFrame\n",
    "predicted_values = predictions.flatten()  # Flatten predictions array\n",
    "\n",
    "# Compute the Mean Squared Error\n",
    "mse = mean_squared_error(actual_values, predicted_values)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, predictions, alpha=0.5, color='blue', label='Predicted vs Actual')\n",
    "plt.text(s=f'MSE: {mse:.5f}', x=y_test.min(), y=y_pred.max(), fontsize=20, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.xlabel('Actual SubhaloBHMass (normalized)',fontsize=16)\n",
    "plt.ylabel('Predicted SubhaloBHMass (normalized)',fontsize=16)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "#plt.legend()\n",
    "plt.text(s=f'MSE: {mse:.5f}', x=y_test.min(), y=y_pred.max(), fontsize=20, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.savefig('NN.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0cf2b-f77b-4838-bdd9-6937d05b0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(random_state=42,max_depth=4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, xgb_y_pred)\n",
    "\n",
    "# Plotting Actual vs. Predicted Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test.iloc[:, 0], y=xgb_y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Ideal line where actual = predicted\n",
    "#plt.title('Actual vs. Predicted Values for SubhaloBHMass',fontsize=20)\n",
    "plt.text(s=f'MSE: {mse_xgb:.5f}', x=y_test.min(), y=y_pred.max(), fontsize=20, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.xlabel('Actual SubhaloBHMass',fontsize=20)\n",
    "plt.ylabel('Predicted SubhaloBHMass',fontsize=20)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.savefig('xgb.jpg')\n",
    "plt.show()\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, xgb_y_pred)\n",
    "print(mse_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e18e22-abe0-4dbd-a886-a48902f1064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "max_depths = [2, 4, 6, 8, 10, 12, 15, 20, 30]\n",
    "mse = []\n",
    "r2=[]\n",
    "roc=[]\n",
    "for i, max_depth in enumerate(max_depths):\n",
    "    xgb = RandomForestRegressor(random_state=42,max_depth=max_depths[i])\n",
    "\n",
    "    # Train the model\n",
    "    xgb.fit(X_train, y_train.values.ravel()) \n",
    "    y_pred_test=xgb.predict(X_test)\n",
    "    \n",
    "    mse += [mean_squared_error(y_test, y_pred_test)]\n",
    "    r2 +=[r2_score(y_test, y_pred_test)]\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths,mse)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths,r2)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('R2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4d545-397e-4028-8c43-3906c2338d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
